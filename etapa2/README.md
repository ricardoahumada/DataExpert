## Reto: **"Construyendo un ETL de exploraci√≥n y pre-procesado"**

**Objetivo del Reto:**  
Evolucionar la soluci√≥n para convertirlo en un ETL que use Numpy y Pandas para realizar un An√°lisis Exploratorio de Datos (EDA) para identificar patrones en el historial de fallos, manejo de valores faltantes y creaci√≥n de variables adicionales. El objetivo es comprender las caracter√≠sticas que pueden afectar el rendimiento y desgaste de los equipos.

Para ello, PowerGen nos ha provisto de 3 fuentes de datos para obtener la informaci√≥n que necesitamos: *Historicos de Ordenes de Trabajo*, *Caracteristicas de los Equipos*, y *Registros de Condiciones*.

Nuestra misi√≥n es analizar y visualizar los datos de mantenimiento de los equipos de una planta energ√©tica, para comprender patrones de fallos, identificar relaciones entre las condiciones operativas de los equipos y sus caracter√≠sticas, y generar visualizaciones que ayuden a prever posibles fallos o necesidades de mantenimiento.


### **Tareas del Reto:**

#### **1. Limpieza y Preprocesamiento de Datos con Python**

  **Objetivo:** Limpiar y preprocesar los tres datasets para que los datos est√©n listos para su an√°lisis.
  
  **Tareas:**
  - Cargar los tres datasets:
    - `Historicos_Ordenes.csv` (√ìrdenes de trabajo)
    - `Registros_Condiciones.csv` (Registros de condiciones operativas)
    - `Caracteristicas_Equipos.csv` (Caracter√≠sticas de los equipos)

  - Opcional: Cargar los datasets de datalake (ver connection string)
   
  
  - Identificar y manejar **valores nulos** en las columnas clave (por ejemplo, `Costo_Mantenimiento`, `Temperatura_C` y `Horas_Operativas`).
  
  - Eliminar **duplicados** y corregir **inconsistencias de formato** (como valores err√≥neos en campos num√©ricos).
  
  - Agregar nuevas columnas relevantes como:
    - **Frecuencia de mantenimiento**: N√∫mero de mantenimientos realizados por equipo.
    - **Vida √∫til estimada**: Estimaci√≥n de la vida √∫til de los equipos basada en las horas operativas.
  
#### **2. An√°lisis Exploratorio de Datos con Python**

  **Objetivo:** Analizar las relaciones entre las caracter√≠sticas de los equipos, el historial de √≥rdenes de trabajo y las condiciones operativas.

  **Tareas:**
  - Realizar un **an√°lisis descriptivo** de los datos:
    - Estad√≠sticas b√°sicas como la media, mediana y desviaci√≥n est√°ndar de las horas operativas, el costo de mantenimiento, y la frecuencia de fallos.
    - Detectar **outliers** en las columnas clave (por ejemplo, en `Costo_Mantenimiento` y `Horas_Operativas`).
  
  - Analizar la **distribuci√≥n de fallos** y **tipos de mantenimiento** (correctivo/preventivo) de los equipos.
  
  - Establecer posibles **correlaciones** entre las variables, como la relaci√≥n entre las **condiciones operativas** (temperatura, vibraci√≥n) y las **horas de operaci√≥n**.
  
  - **Recomendaci√≥n:** Usar t√©cnicas como `groupby()`, `corr()`, visualizaci√≥n de **histogramas** y **diagramas de dispersi√≥n** para detectar patrones y correlaciones.

#### **3. Mezcla y Combinaci√≥n de Datos**

  **Objetivo:** Combinar los tres datasets en un √∫nico conjunto de datos que contenga toda la informaci√≥n relevante de cada equipo, las condiciones operativas y las √≥rdenes de mantenimiento.

  **Tareas:**
  - **Merge**: Utilizar la funci√≥n `merge()` de `pandas` para combinar los tres datasets en un √∫nico dataframe. Las combinaciones deben realizarse a trav√©s de la columna `ID_Equipo` (o cualquier otro identificador √∫nico de equipo).
  
  - Asegurarse de que las columnas combinadas est√©n correctamente alineadas y que no haya **valores nulos** o **duplicados** tras la combinaci√≥n.
  
  - Crear nuevas columnas combinadas que representen relaciones clave:
    - **Tiempo hasta fallo**: ¬øCu√°nto tiempo de operaci√≥n transcurre hasta que un equipo requiere mantenimiento?
    - **Relaci√≥n entre condiciones operativas y fallos**: ¬øC√≥mo impactan la vibraci√≥n o temperatura en la probabilidad de un fallo?
  
  - **Recomendaci√≥n:** Usar `pandas` para realizar los **joins o merges** y la combinaci√≥n de datasets, adem√°s de limpiar los datos resultantes para asegurarse de que no haya errores en los valores.

#### **4. Visualizaci√≥n de Datos**

  **Objetivo:** Crear visualizaciones interesantes para mostrar los hallazgos encontrados durante el an√°lisis y la combinaci√≥n de datos.

  **Tareas:**
  - Crear **gr√°ficas de barras** para mostrar la distribuci√≥n del costo de mantenimiento por tipo de equipo.
  
  - Crear **diagramas de dispersi√≥n** para visualizar la relaci√≥n entre las condiciones operativas (por ejemplo, temperatura y vibraci√≥n) y las horas de operaci√≥n o fallos.
  
  - Crear un **diagrama de caja** para identificar los **outliers** en las horas operativas o costos de mantenimiento.
  
  - Generar una **visualizaci√≥n de la frecuencia de mantenimiento** por tipo de equipo y la relaci√≥n con el tipo de mantenimiento (correctivo/preventivo).
  

#### **5. Carga y Almacenamiento**

  **Objetivo:** Crear visualizaciones interesantes para mostrar los hallazgos encontrados durante el an√°lisis y la combinaci√≥n de datos.
  **Tareas:**
  - Guardar el dataset final en:
    - üìÇ CSV limpio para an√°lisis exploratorio.
    - üóÑÔ∏è PostgreSQL para almacenamiento estructurado.
  - Opcional: Guardar en formato Parquet para optimizar rendimiento.


#### **6. Conclusiones**

  **Objetivo:** Generar un resumen sobre la calidad de los datos y los insights encontrados.
  **Tareas:**
  - Redacta las conclusiones del an√°lisis y limpieza de datos


#### **NOTAS:** 
- Todas las soluciones en Python deben implementarse mediante funciones. Las funciones deben invocarse al final para ejecutar el proceso deseado.
- Usar el kernel: **Python 3.8 - AzureML (Python 3.10.11)**


### **Estructura de carpetas:**
- Carpeta **src** para los `jupyter notebooks` y `archivos` de trabajo  
- Carpeta **dist** para *exportar los jupyter notebooks a m√≥dulos*. (Opcional).
- Los **output** para almacenar archivos *csv*
- Ejemplo: 

```
.
‚îî‚îÄ‚îÄ reposiutorio/
    ‚îú‚îÄ‚îÄ output/
    ‚îÇ   ‚îî‚îÄ‚îÄ [archivos csv o parquet]
    ‚îú‚îÄ‚îÄ dist/
    ‚îÇ   ‚îî‚îÄ‚îÄ [m√≥dulos python]
    ‚îî‚îÄ‚îÄ src/
        ‚îî‚îÄ‚îÄ [archivos jupyter y python]
```


### **Trabajo en equipo:**  
   - Usar un repositorio el com√∫n.
      - Trabajar en la rama "etapa 2"
   - Trabajo por pares:
      - Recomendable abordar las tareas por pares.
   - Dividir las tareas.
   - Recomendaciones:
      - Evitar trabajar en el mismo archivo a la vez. Especialmente los jupyter notebooks.
      - Comunicarse cuando haya commits y pushes para realizar pulls. Evitar en lo posible conflictos.

### **Entregables:**

1. **C√≥digo Python** con la limpieza, preprocesamiento y an√°lisis de datos.
2. **Jupyter Notebook** o archivo de texto que contenga todo el an√°lisis exploratorio realizado, incluyendo los insights obtenidos.
3. **Visualizaciones** generadas para mostrar los patrones y relaciones entre las variables clave.
4. **Conjunto de datos final** (combinado) que puede ser utilizado para realizar modelado predictivo o m√°s an√°lisis.
5. **Almacenamiento final** versi√≥n almacenada de los datos (csv, db, parquet) 

### **Criterios de Evaluaci√≥n:**  

- **Claridad en la limpieza de datos**: Asegurarse de que no hay valores nulos, duplicados ni inconsistencias.
- **Profundidad en el an√°lisis exploratorio**: Evaluaci√≥n de si se han identificado patrones y relaciones importantes en los datos.
- **Calidad de las visualizaciones**: Gr√°ficos claros, informativos y bien estructurados.
- **Calidad de la combinaci√≥n de los datasets**: La combinaci√≥n de datos ha sido exitosa y que el conjunto de datos resultante est√° listo para los siguientes pasos de modelado predictivo.